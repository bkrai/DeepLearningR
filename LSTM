# Libraries required
library(keras)

#imdb data
imdb <- dataset_imdb(num_words = 500) 
c(c(train_x, train_y), c(test_x, test_y)) %<-% imdb
length(train_x); length(test_x)

table(train_y)
table(test_y)

# Padding sequences
train_x <- pad_sequences(train_x, maxlen = 100) 
test_x <- pad_sequences(test_x, maxlen = 100)

# Model
model <- keras_model_sequential() 
model %>% 
         layer_embedding(input_dim = 500, output_dim = 32) %>%
         layer_simple_rnn(units = 32) %>%  
         layer_dense(units = 1, activation = "sigmoid")

# Compile
model %>% compile(optimizer = "rmsprop",
         loss = "binary_crossentropy",
         metrics = c("acc"))

# Fit model
history <- model %>% fit(train_x, train_y,
         epochs = 25,
         batch_size = 128,
         validation_split = 0.2)
plot(history)

# Prediction
model %>% evaluate(train_x, train_y)
pred <- model %>%   predict(train_x)
pred <- ifelse(pred <0.5, 0, 1)
table(Predicted=pred, Actual=imdb$train$y)

model %>% evaluate(test_x, test_y)
pred1 <- model %>%   predict(test_x)
pred1 <- ifelse(pred1 <0.5, 0, 1)
table(Predicted=pred1, Actual=imdb$test$y)
